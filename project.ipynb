{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5ecf45",
   "metadata": {},
   "source": [
    "Installing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b4c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install datasets scikit-learn torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d00afe",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0521b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0ec839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a04a4",
   "metadata": {},
   "source": [
    "Load the datasets from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e360640",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"civil_comments\",split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedf023",
   "metadata": {},
   "source": [
    "Here I am loading 3000 data only to  reduce the moddel training time by saving some space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670886d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = dataset.select(range(3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186c072",
   "metadata": {},
   "source": [
    "Converting into Dataframe to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98032ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = small_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2a98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"toxicity\"]>=.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e819fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This story gets more ridiculous by the hour! A...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Angry trolls, misogynists and Racists\", oh my....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>In his letter, Cook also makes the entirely co...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>Every government is prone to tyranny unless th...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>\"40-20\\n12 hours ago\\nLabeling others with the...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>\"This law subverts our ability to be watchful....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>You are stating the same sort of conspiracy th...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxicity  \\\n",
       "4                  haha you guys are a bunch of losers.  0.893617   \n",
       "5                                  ur a sh*tty comment.  0.666667   \n",
       "13    It's ridiculous that these guys are being call...  0.600000   \n",
       "14    This story gets more ridiculous by the hour! A...  0.500000   \n",
       "19    Angry trolls, misogynists and Racists\", oh my....  0.500000   \n",
       "...                                                 ...       ...   \n",
       "2964  In his letter, Cook also makes the entirely co...  0.600000   \n",
       "2974  Every government is prone to tyranny unless th...  0.700000   \n",
       "2989  \"40-20\\n12 hours ago\\nLabeling others with the...  0.600000   \n",
       "2991  \"This law subverts our ability to be watchful....  0.500000   \n",
       "2994  You are stating the same sort of conspiracy th...  0.500000   \n",
       "\n",
       "      severe_toxicity   obscene  threat    insult  identity_attack  \\\n",
       "4            0.021277  0.000000     0.0  0.872340         0.021277   \n",
       "5            0.047619  0.638095     0.0  0.333333         0.000000   \n",
       "13           0.000000  0.100000     0.1  0.600000         0.000000   \n",
       "14           0.000000  0.000000     0.0  0.300000         0.000000   \n",
       "19           0.000000  0.000000     0.0  0.500000         0.100000   \n",
       "...               ...       ...     ...       ...              ...   \n",
       "2964         0.000000  0.200000     0.0  0.600000         0.000000   \n",
       "2974         0.000000  0.000000     0.2  0.200000         0.700000   \n",
       "2989         0.000000  0.000000     0.0  0.500000         0.500000   \n",
       "2991         0.000000  0.100000     0.2  0.400000         0.200000   \n",
       "2994         0.000000  0.000000     0.0  0.500000         0.100000   \n",
       "\n",
       "      sexual_explicit  \n",
       "4            0.000000  \n",
       "5            0.009524  \n",
       "13           0.000000  \n",
       "14           0.000000  \n",
       "19           0.000000  \n",
       "...               ...  \n",
       "2964         0.000000  \n",
       "2974         0.000000  \n",
       "2989         0.000000  \n",
       "2991         0.000000  \n",
       "2994         0.000000  \n",
       "\n",
       "[139 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeadc51",
   "metadata": {},
   "source": [
    "Test-Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "befb0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = small_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473bd44",
   "metadata": {},
   "source": [
    "Add binary Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9622d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2400/2400 [00:00<00:00, 7520.22 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 15951.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_label(row):\n",
    "    row[\"label\"] = 1 if row[\"toxicity\"] >= 0.5 else 0\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(add_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2728570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset['train'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314b0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1=df_train[df_train[\"label\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8a8412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I am not concerned about the \"privacy, persona...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Took this as an opportunity to check back in o...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tim: \"...randomizing who gets what comment on ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Liars Anonymous meeting today will be at 4...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Well shit, they drafted a guide.  We should al...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>If I recall correctly did not LTD just announc...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>Considering the real facts of this issue, I be...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>They are all equally odious , not for the view...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>My goodness....Do you really think a politicia...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxicity  \\\n",
       "10    I am not concerned about the \"privacy, persona...  0.600000   \n",
       "22    Took this as an opportunity to check back in o...  0.700000   \n",
       "42    Tim: \"...randomizing who gets what comment on ...  0.500000   \n",
       "46    The Liars Anonymous meeting today will be at 4...  1.000000   \n",
       "68    Well shit, they drafted a guide.  We should al...  0.818182   \n",
       "...                                                 ...       ...   \n",
       "2364  Yet call out all Muslims for the acts of a few...  0.912500   \n",
       "2366  If I recall correctly did not LTD just announc...  0.500000   \n",
       "2373  Considering the real facts of this issue, I be...  0.700000   \n",
       "2386  They are all equally odious , not for the view...  0.750000   \n",
       "2390  My goodness....Do you really think a politicia...  0.500000   \n",
       "\n",
       "      severe_toxicity   obscene    threat    insult  identity_attack  \\\n",
       "10           0.000000  0.000000  0.200000  0.500000         0.300000   \n",
       "22           0.100000  0.000000  0.000000  0.700000         0.000000   \n",
       "42           0.000000  0.000000  0.000000  0.500000         0.300000   \n",
       "46           0.000000  0.000000  0.000000  1.000000         0.000000   \n",
       "68           0.045455  0.772727  0.015152  0.287879         0.000000   \n",
       "...               ...       ...       ...       ...              ...   \n",
       "2364         0.050000  0.237500  0.112500  0.887500         0.612500   \n",
       "2366         0.000000  0.300000  0.000000  0.500000         0.000000   \n",
       "2373         0.000000  0.300000  0.100000  0.600000         0.000000   \n",
       "2386         0.016667  0.133333  0.000000  0.716667         0.116667   \n",
       "2390         0.000000  0.000000  0.000000  0.500000         0.000000   \n",
       "\n",
       "      sexual_explicit  label  \n",
       "10                0.0      1  \n",
       "22                0.0      1  \n",
       "42                0.0      1  \n",
       "46                0.0      1  \n",
       "68                0.0      1  \n",
       "...               ...    ...  \n",
       "2364              0.0      1  \n",
       "2366              0.0      1  \n",
       "2373              0.0      1  \n",
       "2386              0.0      1  \n",
       "2390              0.0      1  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95015fb6",
   "metadata": {},
   "source": [
    "Tokenize the text-\n",
    "DistilBERT tokenizer to tokenize the inputs is used. tuncate=true, padding=True and max_Length=128 to maintain the length of the input list to max-length by truncating the long length list and padding with extra 0 to shorter length list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d12f7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2400/2400 [00:00<00:00, 18859.14 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 19421.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(row):\n",
    "    return tokenizer(row[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4a866",
   "metadata": {},
   "source": [
    "Loading the pretrained \"distilbert-base-uncased\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75fbedbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c8439",
   "metadata": {},
   "source": [
    "Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d10cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d444fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5747913",
   "metadata": {},
   "source": [
    "Define the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07db9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1 = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55bd08",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86b1cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/njm34s9x093gvdl21tlkbt2h0000gq/T/ipykernel_90012/3025579641.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.170900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.161343518892924, metrics={'train_runtime': 59.8595, 'train_samples_per_second': 80.188, 'train_steps_per_second': 10.023, 'total_flos': 158960878387200.0, 'train_loss': 0.161343518892924, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5a7fa",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c2178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a loser person! --> unsafe\n",
      "I need help with my order. --> safe\n",
      "You're trash and no one likes you. --> unsafe\n",
      "Can you assist me with my laptop? --> safe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Force CPU for inference\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to classify a user prompt as \"safe\" or \"unsafe\"\n",
    "def classify_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = outputs.logits.argmax(dim=-1).item()\n",
    "    return \"unsafe\" if prediction == 1 else \"safe\"\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"You're a loser person!\",\n",
    "    \"I need help with my order.\",\n",
    "    \"You're trash and no one likes you.\",\n",
    "    \"Can you assist me with my laptop?\",\n",
    "    \n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    print(f\"{p} --> {classify_prompt(p)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
