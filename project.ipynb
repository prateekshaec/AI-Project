{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5ecf45",
   "metadata": {},
   "source": [
    "Installing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b4c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install datasets scikit-learn torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d00afe",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0521b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateeksha/Desktop/Agentioc AI/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0ec839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a04a4",
   "metadata": {},
   "source": [
    "Load the datasets from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e360640",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"civil_comments\",split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedf023",
   "metadata": {},
   "source": [
    "Here I am loading 3000 data only to  reduce the moddel training time by saving some space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670886d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = dataset.select(range(3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186c072",
   "metadata": {},
   "source": [
    "Converting into Dataframe to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98032ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = small_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2a98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"toxicity\"]>=.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e819fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This story gets more ridiculous by the hour! A...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Angry trolls, misogynists and Racists\", oh my....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>In his letter, Cook also makes the entirely co...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>Every government is prone to tyranny unless th...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>\"40-20\\n12 hours ago\\nLabeling others with the...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>\"This law subverts our ability to be watchful....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>You are stating the same sort of conspiracy th...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxicity  \\\n",
       "4                  haha you guys are a bunch of losers.  0.893617   \n",
       "5                                  ur a sh*tty comment.  0.666667   \n",
       "13    It's ridiculous that these guys are being call...  0.600000   \n",
       "14    This story gets more ridiculous by the hour! A...  0.500000   \n",
       "19    Angry trolls, misogynists and Racists\", oh my....  0.500000   \n",
       "...                                                 ...       ...   \n",
       "2964  In his letter, Cook also makes the entirely co...  0.600000   \n",
       "2974  Every government is prone to tyranny unless th...  0.700000   \n",
       "2989  \"40-20\\n12 hours ago\\nLabeling others with the...  0.600000   \n",
       "2991  \"This law subverts our ability to be watchful....  0.500000   \n",
       "2994  You are stating the same sort of conspiracy th...  0.500000   \n",
       "\n",
       "      severe_toxicity   obscene  threat    insult  identity_attack  \\\n",
       "4            0.021277  0.000000     0.0  0.872340         0.021277   \n",
       "5            0.047619  0.638095     0.0  0.333333         0.000000   \n",
       "13           0.000000  0.100000     0.1  0.600000         0.000000   \n",
       "14           0.000000  0.000000     0.0  0.300000         0.000000   \n",
       "19           0.000000  0.000000     0.0  0.500000         0.100000   \n",
       "...               ...       ...     ...       ...              ...   \n",
       "2964         0.000000  0.200000     0.0  0.600000         0.000000   \n",
       "2974         0.000000  0.000000     0.2  0.200000         0.700000   \n",
       "2989         0.000000  0.000000     0.0  0.500000         0.500000   \n",
       "2991         0.000000  0.100000     0.2  0.400000         0.200000   \n",
       "2994         0.000000  0.000000     0.0  0.500000         0.100000   \n",
       "\n",
       "      sexual_explicit  \n",
       "4            0.000000  \n",
       "5            0.009524  \n",
       "13           0.000000  \n",
       "14           0.000000  \n",
       "19           0.000000  \n",
       "...               ...  \n",
       "2964         0.000000  \n",
       "2974         0.000000  \n",
       "2989         0.000000  \n",
       "2991         0.000000  \n",
       "2994         0.000000  \n",
       "\n",
       "[139 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeadc51",
   "metadata": {},
   "source": [
    "Test-Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "befb0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = small_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473bd44",
   "metadata": {},
   "source": [
    "Add binary Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9622d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2400/2400 [00:00<00:00, 5970.88 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 13009.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_label(row):\n",
    "    row[\"label\"] = 1 if row[\"toxicity\"] >= 0.5 else 0\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(add_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2728570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset['train'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314b0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1=df_train[df_train[\"label\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8a8412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Silat you are a moron</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Um. Bernie supporters attack.  Thom Hartmann a...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Some people are so dumb that they will vote fo...</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>\"Anybody who can kiss that many asses, that qu...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>On its face, Glueck's claim that AG Rosenblum ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>This couple is just milking this....the city s...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>Where do you get the Sour Grapes to say this i...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>Dear world:\\nJust a reminder that none of thes...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>That guy was a moron, anyone stupid enough to ...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxicity  \\\n",
       "13                                Silat you are a moron  0.903226   \n",
       "62    Um. Bernie supporters attack.  Thom Hartmann a...  0.500000   \n",
       "96    Some people are so dumb that they will vote fo...  0.611940   \n",
       "107   \"Anybody who can kiss that many asses, that qu...  0.600000   \n",
       "117   On its face, Glueck's claim that AG Rosenblum ...  0.500000   \n",
       "...                                                 ...       ...   \n",
       "2288  It's ridiculous that these guys are being call...  0.600000   \n",
       "2291  This couple is just milking this....the city s...  0.800000   \n",
       "2298  Where do you get the Sour Grapes to say this i...  1.000000   \n",
       "2318  Dear world:\\nJust a reminder that none of thes...  1.000000   \n",
       "2355  That guy was a moron, anyone stupid enough to ...  0.919355   \n",
       "\n",
       "      severe_toxicity   obscene    threat    insult  identity_attack  \\\n",
       "13           0.064516  0.145161  0.000000  0.887097         0.000000   \n",
       "62           0.000000  0.000000  0.000000  0.500000         0.000000   \n",
       "96           0.000000  0.089552  0.000000  0.611940         0.000000   \n",
       "107          0.000000  0.500000  0.000000  0.500000         0.100000   \n",
       "117          0.000000  0.000000  0.000000  0.500000         0.000000   \n",
       "...               ...       ...       ...       ...              ...   \n",
       "2288         0.000000  0.100000  0.100000  0.600000         0.000000   \n",
       "2291         0.000000  0.500000  0.000000  0.300000         0.000000   \n",
       "2298         0.000000  1.000000  0.000000  1.000000         0.000000   \n",
       "2318         0.000000  0.000000  0.000000  1.000000         0.000000   \n",
       "2355         0.145161  0.177419  0.225806  0.919355         0.016129   \n",
       "\n",
       "      sexual_explicit  label  \n",
       "13                0.0      1  \n",
       "62                0.0      1  \n",
       "96                0.0      1  \n",
       "107               0.5      1  \n",
       "117               0.0      1  \n",
       "...               ...    ...  \n",
       "2288              0.0      1  \n",
       "2291              0.3      1  \n",
       "2298              0.0      1  \n",
       "2318              0.0      1  \n",
       "2355              0.0      1  \n",
       "\n",
       "[114 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95015fb6",
   "metadata": {},
   "source": [
    "Tokenize the text-\n",
    "DistilBERT tokenizer to tokenize the inputs is used. tuncate=true, padding=True and max_Length=128 to maintain the length of the input list to max-length by truncating the long length list and padding with extra 0 to shorter length list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d12f7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2400/2400 [00:00<00:00, 12543.90 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 15338.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(row):\n",
    "    return tokenizer(row[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4a866",
   "metadata": {},
   "source": [
    "Loading the pretrained \"distilbert-base-uncased\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75fbedbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c8439",
   "metadata": {},
   "source": [
    "Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d10cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d444fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5747913",
   "metadata": {},
   "source": [
    "Define the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07db9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1 = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55bd08",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5a7fa",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Force CPU for inference\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to classify a user prompt as \"safe\" or \"unsafe\"\n",
    "def classify_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = outputs.logits.argmax(dim=-1).item()\n",
    "    return \"unsafe\" if prediction == 1 else \"safe\"\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"You're a loser person!\",\n",
    "    \"I need help with my order.\",\n",
    "    \"You're trash and no one likes you.\",\n",
    "    \"Can you assist me with my laptop?\",\n",
    "    \n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    print(f\"{p} --> {classify_prompt(p)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
